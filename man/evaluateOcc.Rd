% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluateOcc.R
\name{evaluateOcc}
\alias{evaluateOcc}
\title{Model evaluation / accuracy assessment for \code{\link{trainOcc}} objects.}
\usage{
evaluateOcc(x, te.u, te.y, positive = NULL, th = NULL, allModels = FALSE,
  modParam = NULL, modRow = NULL, modRank = NULL, by = NULL,
  decreasing = TRUE, verbose = FALSE, ...)
}
\arguments{
\item{x}{an object of class \code{\link{trainOcc}}}

\item{te.u}{the data to predict on.}

\item{te.y}{a vector of observed  positive/negative (presence/absence) values}

\item{positive}{the positive label in te.y. if this is not given, the class with the lower frequency is assumed to be the positive class.}

\item{th}{a vector of thresholds at which the model is evaluated}

\item{allModels}{logical, default is \code{FALSE}. Set to \code{TRUE} if all models should be evaluated.}

\item{modParam}{data frame with the parameters of the model to be evaluated}

\item{modRow}{the row of the model in the \code{x$results} table.}

\item{modRank}{the rank of the model after sorting by \code{by}.}

\item{by}{character. must be a metric available in the \code{x$results} table by which to sort. 
If \code{NULL} the performance metric is taken from the \code{train} object. see also \code{\link{sort.train}}}

\item{decreasing}{only when \code{modRank} is used. \code{TRUE} (default) to sort in decreasing order. Can be a vector if \code{by} is a vector.}

\item{verbose}{\code{FALSE}, set to \code{TRUE} if you want to see the progress}

\item{...}{arguments passed to \code{\link[dismo]{evaluate}} from the \code{dismo} package.}
}
\value{
an object of class ModelEvaluation 
(see \code{\link{ModelEvaluation-class}})) 
or ModelSelectionEvaluation. The latter is a list with two elements, the 
first containing the model sleetion table and the second a list with the evaluation 
results, each of whith a \code{ModelEvaluation} object. 
The rows in model selection table correspond to the evaluation list elements.
}
\description{
Calculation of accuracy for specified thresholds.  
\code{\link[dismo]{evaluate}} is called to perform the calculations.
}
\details{
By defalut, only the final model is evaluated when \code{allModels} is \code{FALSE} 
and non of the arguments \code{modParam},\code{modRow}, or \code{modRank} given.
}
\examples{
\dontrun{
# get training and test data
data(bananas)
seed <- 123456
tr.x <- bananas$tr[, -1]
tr.y <- bananas$tr[, 1]
set.seed (seed)
te.i <- sample ( ncell (bananas$y), 1000 )
te.x <- extract (bananas$x, te.i)
te.y <- extract (bananas$y, te.i)
# run trainOcc 
oc <- trainOcc(x=tr.x, y=puFactor(tr.y), 
               tuneGrid=expand.grid(sigma=c(0.1,1), ### not so large grid
                                    cNeg=2^seq(-5, 10, 3), 
                                    cMultiplier=2^seq(4, 15, 2)))
# evaluate the final model
ev <- evaluateOcc(oc, y=te.y, te.u=te.x)
# besides the thresholds used, this is identical to: 
te.pred <- predict(oc, te.x)
ev <- evaluate(p=te.pred[te.y==1], a=te.pred[te.y!=1])
# evaluate several models
# e.g. evaluate models with a true positive rate (tpr) higher than 0.8 and a 
# positive prediction probability (ppp) small than 0.4
modRows <- which(oc$results$tpr>=0.8 & oc$results$ppp<0.4)
ev <- evaluateOcc(oc, y=te.y, te.u=te.x, modRow=modRows)
# plot the pu-performance metric versus the maximum kappa 
evList <- print(ev)
plot(evList$puF, evList$mxK.K, xlab="puF", ylab="max. Kappa")
}
}

