% Generated by roxygen2 (4.0.1): do not edit by hand
\name{trainOcc}
\alias{trainOcc}
\title{Fit a one-class classification model over Different Tuning Parameters.}
\usage{
trainOcc(x, y, positive = NULL, method = "biasedsvm", metric = NULL,
  trControl = NULL, index = NULL, allowParallel = TRUE,
  verboseIter = TRUE, ...)
}
\arguments{
\item{x}{a data frame with the training data. The samples are in the rows and the features in the columns.}

\item{y}{a vector containing the labels encoding if a sample is positive or unlabeled.}

\item{positive}{The positive class in \code{y}.}

\item{method}{a one-class classification method. Implemented are \code{ocsvm} (one-class SVM, via \code{\link[kernlab]{ksvm}}), \code{biasedsvm} (biased SVM, via \code{\link[kernlab]{ksvm}}), \code{maxent} (via \code{\link[dismo]{maxent}}), or a costum method that can be passed to \code{\link{train}}.}

\item{metric}{A performance metric for positive/unlabeled data used for model selection.
Default for \code{ocsvm} and  \code{biasedsvm} is \code{puF} and for \code{maxent} \code{puAuc}.}

\item{trControl}{see \code{\link{train}} and \code{\link{trainControl}}.
If this argument is given, make sure that it makes sense (see details).}

\item{index}{a list of training indices for the resampling iterations. This will be passed
to the identically names argument of the \code{\link{trainControl}} function unless the argument \code{trControl} is not \code{NULL}.}

\item{allowParallel}{enable or disable parallel processing. Even if \code{TRUE}, parallel processing is only possible if a parallel backend is loaded and available.}

\item{verboseIter}{Logical for printing progress, does only work if parallel processing is disabled (defaults to \code{TRUE}).}

\item{...}{other arguments that can be passed to train. Be careful with trainControl... !}
}
\value{
A \code{\link{trainOcc}} object with is a child of the object \code{train}.
}
\description{
This function calculates resampling based performance measures over a
grid of tuning parameters for one of the implemented classifiers (one-class SVM,
biased SVM, maxent).
}
\details{
\code{trainOcc} calls \code{\link{train}} and returns an object of class
\code{trainOcc} which is a child of \code{train}, i.e. methods defined in \code{caret}
for \code{train} can also be used. \cr
Via the \code{trControl} argument you can customize the way how train acts
(see \code{\link{trainControl}}) but note the following (see also the example, where the (trainOcc-) defaults of
\code{trControl} are given):
\itemize{
\item{make sure that you define a suitable \code{summaryFunction} functions which
defines returns metrics for positive/unlabeled data (default: \code{\link{puSummary}}).}
\item{\code{classProbs} has to be set to \code{TRUE} if the continuous outputs of
the one-class classifier are required to calculate all performance metric(s), i.e. the ones
which rely on the continuous predictions, such as the \code{puAuc}.}
\item{\code{savePredictions} and \code{returnResamp} should also be set to
\code{TRUE} in order to make all diagnostic methods available for later analaysis. }
}
}
\examples{
\dontrun{
## a synthetic data set
data(bananas)

## this is the default setting of trControl in trainOcc
cntrl <- trainControl(method = "cv",
                      number = 10,
                      summaryFunction = puSummary, #!
                      classProbs = TRUE,           #!
                      savePredictions = TRUE,      #!
                      returnResamp = "all",        #!
                      allowParallel = TRUE)

## but lets use repeated k-fold cross-validation
set.seed(123)
rcv.idx <- createMultiFolds(puFactor(bananas$tr[,1]), k=5, times=5)
cntrl <- trainControl(index = rcv.idx,
                      summaryFunction = puSummary,
                      classProbs = TRUE,
                      savePredictions = TRUE,
                      returnResamp = "all",
                      allowParallel = TRUE)

tocc <- trainOcc(x=bananas$tr[, -1], y=bananas$tr[, 1], trControl=cntrl)

## be aware that the PU-performance metrics are not always choosing the
## optimal model
## you may want to investigate other performance metrics stored in the
## model selection table.
tocc

## neatly arranged by sorting
sort(tocc, by="puF")

## particularly the true positive rate (tpr) and the probability of
## positive prediction (ppp) are informative. you want to find a model
## with high tpr but low ppp.
plot_PPPvsTPR(tocc)

## based on this plot you may want to select candidate models for more
## thoroughly evaluation: use identifyPoints=TRUE
\dontrun{ candiModels <- plot_PPPvsTPR(tocc, identifyPoints=TRUE) }

## the former assignment returns a list like the one created here:
candiModels <- modelPosition(tocc, modRow=c(80, 86, 44))

## plot the resampling distributions
resamps <- resamples(tocc, modRow=candiModels$row)
bwplot(resamps, scales="free")

## also the diagnostic distributions plot can be help
## therefore (a large subset of ) the unlabeled data needs to be predicted
tocc.m80 <- update(tocc, modRow=candiModels$row[1]) # set the final model
pred.m80 <- predict(tocc, bananas$x)                # predict
tocc.m86 <- update(tocc, modRow=candiModels$row[2])
pred.m86 <- predict(tocc, bananas$x)
tocc.m44 <- update(tocc, modRow=candiModels$row[3])
pred.m44 <- predict(tocc, bananas$x)

par(mfrow=c(1,3))
hist(tocc.m80, pred.m80, th=0)
hist(tocc.m86, pred.m86, th=0)
hist(tocc.m44, pred.m44, th=0)

## here we can also see the model in the 2D feature space. this is usually
## not possible because the feature space is high diminsional.
par(mfrow=c(1,1))
featurespace(tocc.m80, th=0)
featurespace(tocc.m86, th=0)
featurespace(tocc.m44, th=0)
}
}

